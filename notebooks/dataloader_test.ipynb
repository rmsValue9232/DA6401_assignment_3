{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ea7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a39c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import vanilla_model\n",
    "import attention_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19bf0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi.translit.sampled.dev.tsv',\n",
       " 'hi.translit.sampled.test.tsv',\n",
       " 'hi.translit.sampled.train.tsv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e2f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac6478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm = dataloader.DakshinaDataModule(\n",
    "    train_file = os.path.join(BASE_PATH, 'hi.translit.sampled.train.tsv'),\n",
    "    val_file = os.path.join(BASE_PATH, 'hi.translit.sampled.dev.tsv'),\n",
    "    test_file = os.path.join(BASE_PATH, 'hi.translit.sampled.test.tsv'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8cf0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1968ecc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': tensor([1, 3, 4, 2]), 'tgt': tensor([1, 3, 4, 2])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddm.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af866dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  src_input: torch.Size([32, 16])\n",
      "  src_len: torch.Size([32])\n",
      "  tgt_input: torch.Size([32, 17])\n",
      "  tgt_len: torch.Size([32])\n",
      "  tgt_output: torch.Size([32, 17])\n",
      "Batch 1:\n",
      "  src_input: torch.Size([32, 15])\n",
      "  src_len: torch.Size([32])\n",
      "  tgt_input: torch.Size([32, 16])\n",
      "  tgt_len: torch.Size([32])\n",
      "  tgt_output: torch.Size([32, 16])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(ddm.train_dataloader()):\n",
    "    if i == 2:\n",
    "        break\n",
    "    print(f'Batch {i}:')\n",
    "    for k, v in batch.items():\n",
    "        print(f'  {k}: {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e406c818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 14, 12, 18, 13, 20, 57,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  5, 20, 31, 18, 23, 20,  9, 18, 28,  5,  2,  0,  0,  0],\n",
       "        [ 1, 28, 24, 28, 40,  9, 18,  9, 21,  2,  0,  0,  0,  0,  0],\n",
       "        [ 1, 29, 18, 12,  8, 34, 10,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 36,  4, 26, 21, 31,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 33, 42, 36, 18, 34,  8, 29, 10,  2,  0,  0,  0,  0,  0],\n",
       "        [ 1, 36, 28, 36, 18, 23, 20,  6, 18, 12, 36, 18,  9,  2,  0],\n",
       "        [ 1,  6, 11,  4, 30, 20,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 20, 15, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 14, 18, 31,  8, 36, 18,  9, 12, 21, 23,  2,  0,  0,  0],\n",
       "        [ 1, 36, 20, 23, 28, 15,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 36, 11, 27,  8,  4,  9,  8,  9,  2,  0,  0,  0,  0,  0],\n",
       "        [ 1, 34, 11, 12, 20,  9, 20,  9, 18,  9, 18, 31,  8,  5,  2],\n",
       "        [ 1, 27, 25, 28, 15, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 28, 33, 48,  8, 10, 24,  4,  2,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 28, 12, 18, 27, 16,  4, 29,  2,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  5, 10, 18, 34, 31, 35,  5, 18, 19,  2,  0,  0,  0,  0],\n",
       "        [ 1, 46,  9, 12, 34, 11, 12,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 31, 15, 31, 20, 36,  8, 23, 24,  4,  2,  0,  0,  0,  0],\n",
       "        [ 1, 31,  8, 12, 16, 27,  5,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  5, 20, 15, 20,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 30, 16, 50, 10, 21,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 36, 11, 15, 20, 12, 21,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 33, 12, 36,  8,  4,  6, 20, 12,  2,  0,  0,  0,  0,  0],\n",
       "        [ 1, 31, 20, 19, 18, 34,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 12, 20, 26, 17, 31, 15,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  5, 16, 12, 24, 10,  8, 15, 20,  2,  0,  0,  0,  0,  0],\n",
       "        [ 1, 44, 11, 10,  9, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 36,  9, 21, 36, 12,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 34, 20,  4, 27, 31, 21,  4,  2,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 17,  5, 18,  9,  8, 23, 11,  5, 18,  9,  2,  0,  0,  0],\n",
       "        [ 1,  9, 20, 12, 18,  5,  8,  5,  2,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0 = next(iter(ddm.train_dataloader()))\n",
    "batch0['src_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a599fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = vanilla_model.VanillaSeq2Seq(\n",
    "    input_vocab_size = len(ddm.input_vocab.idx2char),\n",
    "    target_vocab_size = len(ddm.target_vocab.idx2char),\n",
    "    embedding_dim = 256,\n",
    "    hidden_dim = 512,\n",
    "    encoder_layers = 2,\n",
    "    decoder_layers = 2,\n",
    "    encoder_dropout = 0.0,\n",
    "    decoder_dropout = 0.0,\n",
    "    encoding_unit = 'rnn',\n",
    "    decoding_unit = 'rnn',\n",
    "    lr = 1e-3,\n",
    "    optimizer = 'adam',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3546eedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.7585e-04,  6.1579e-02, -1.2477e-01,  ...,  6.8627e-02,\n",
       "           7.5931e-02, -9.4983e-02],\n",
       "         [ 1.0894e-02, -2.6695e-01,  1.7374e-01,  ...,  3.1440e-02,\n",
       "           5.1228e-02,  2.4525e-01],\n",
       "         [ 6.9800e-02,  1.9067e-02, -5.2559e-02,  ...,  3.5842e-02,\n",
       "           1.3402e-01, -1.3506e-01],\n",
       "         ...,\n",
       "         [-3.3987e-01, -3.5471e-01, -9.3559e-03,  ..., -1.4440e-02,\n",
       "           4.7809e-02, -1.1106e-01],\n",
       "         [-4.8556e-01, -3.2035e-01, -3.3951e-03,  ..., -1.2127e-03,\n",
       "           9.7428e-02, -1.2021e-01],\n",
       "         [-5.3128e-01, -2.9397e-01,  2.1655e-02,  ..., -1.5243e-02,\n",
       "           1.1639e-01, -1.4193e-01]],\n",
       "\n",
       "        [[-9.8269e-02, -3.2638e-04, -5.2699e-02,  ...,  8.6578e-02,\n",
       "          -4.7785e-02,  3.6666e-02],\n",
       "         [-1.7827e-01, -3.0714e-01,  9.4189e-02,  ...,  2.8649e-01,\n",
       "           6.8893e-02,  4.0426e-01],\n",
       "         [-1.1548e-01,  1.1968e-01,  5.4504e-02,  ..., -2.8071e-01,\n",
       "          -1.4401e-02, -8.0366e-02],\n",
       "         ...,\n",
       "         [-3.5817e-01, -4.2741e-01,  9.3336e-02,  ...,  1.0396e-01,\n",
       "          -7.5364e-02,  1.0304e-01],\n",
       "         [-3.8781e-01, -4.0992e-01,  1.0674e-02,  ...,  7.4467e-02,\n",
       "          -1.3549e-02, -7.6292e-02],\n",
       "         [-5.2107e-01, -3.1347e-01,  1.7512e-02,  ..., -8.0004e-02,\n",
       "           7.9273e-02, -1.1448e-01]],\n",
       "\n",
       "        [[-7.4774e-02, -6.7611e-02, -5.3458e-02,  ...,  1.3743e-01,\n",
       "          -1.3480e-02, -3.2161e-02],\n",
       "         [ 1.5216e-01, -2.5570e-02,  2.9136e-02,  ..., -8.6210e-02,\n",
       "          -7.6870e-02,  2.7512e-02],\n",
       "         [-1.7426e-01,  1.4690e-01, -1.4152e-01,  ...,  2.2566e-01,\n",
       "           3.7567e-02, -1.4632e-01],\n",
       "         ...,\n",
       "         [-3.6553e-01, -3.2860e-01, -1.8673e-03,  ..., -3.6786e-02,\n",
       "          -7.9982e-03, -3.8274e-02],\n",
       "         [-4.7819e-01, -3.3798e-01,  2.6230e-02,  ..., -4.6858e-02,\n",
       "           8.3768e-02, -1.1086e-01],\n",
       "         [-5.2650e-01, -2.8993e-01,  3.6590e-02,  ..., -2.2857e-03,\n",
       "           1.0187e-01, -1.6524e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6364e-01, -4.0499e-02, -2.2645e-02,  ...,  6.6174e-02,\n",
       "          -5.3732e-02, -2.0359e-01],\n",
       "         [-1.1944e-01, -2.7325e-01, -1.6936e-01,  ...,  2.8555e-01,\n",
       "          -4.5448e-02,  1.4524e-01],\n",
       "         [-3.1901e-02,  2.8883e-02, -7.8800e-02,  ..., -1.3277e-01,\n",
       "           1.4180e-02, -1.2508e-01],\n",
       "         ...,\n",
       "         [-1.9215e-01, -3.2102e-01,  1.0446e-01,  ...,  1.2705e-01,\n",
       "           3.4217e-02, -1.4378e-02],\n",
       "         [-3.3844e-01, -3.1651e-01, -2.3664e-02,  ...,  7.5365e-03,\n",
       "          -2.9890e-03, -7.3179e-02],\n",
       "         [-4.8258e-01, -3.4073e-01, -1.7877e-02,  ..., -2.3486e-02,\n",
       "           1.0816e-01, -9.8397e-02]],\n",
       "\n",
       "        [[-8.0041e-02, -2.8985e-02,  5.8808e-02,  ...,  5.5785e-02,\n",
       "          -9.6058e-05, -1.5260e-01],\n",
       "         [ 8.1844e-02, -2.0704e-01, -1.4661e-01,  ...,  1.2467e-01,\n",
       "          -8.2071e-02,  1.2725e-01],\n",
       "         [ 1.0326e-01, -5.5143e-03, -1.7268e-01,  ..., -5.1441e-02,\n",
       "          -1.5071e-02, -8.4217e-02],\n",
       "         ...,\n",
       "         [ 1.1499e-01, -1.9213e-01,  1.9310e-01,  ...,  1.3629e-01,\n",
       "           8.1058e-02,  6.3292e-02],\n",
       "         [-3.7107e-01, -3.9379e-01,  1.4575e-01,  ...,  1.7053e-01,\n",
       "          -8.4239e-02, -4.9479e-02],\n",
       "         [-3.7088e-01, -3.8446e-01,  3.6716e-02,  ...,  4.1033e-03,\n",
       "           3.6088e-03, -4.3789e-02]],\n",
       "\n",
       "        [[-2.5806e-02, -2.8575e-02, -6.4076e-02,  ...,  3.4398e-02,\n",
       "          -1.3271e-02,  5.4765e-02],\n",
       "         [-9.0782e-02, -1.7881e-01,  7.9703e-02,  ...,  1.5100e-01,\n",
       "          -2.8422e-03,  1.0830e-01],\n",
       "         [ 3.2345e-02,  1.3813e-01,  1.4022e-01,  ...,  1.5569e-02,\n",
       "           8.6561e-02, -4.7972e-02],\n",
       "         ...,\n",
       "         [-5.4366e-01, -2.7579e-01,  8.1260e-03,  ..., -2.4836e-02,\n",
       "           1.1554e-01, -1.4590e-01],\n",
       "         [-4.9757e-01, -3.1069e-01,  8.2689e-03,  ..., -4.7654e-02,\n",
       "           1.3545e-01, -1.5349e-01],\n",
       "         [-4.9348e-01, -3.0321e-01,  1.3538e-02,  ..., -3.0040e-02,\n",
       "           1.1670e-01, -1.5573e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = seq_model(batch0['src_input'], batch0['src_len'], batch0['tgt_input'])\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de7d98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 14, 29])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d39175",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, acc, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mseq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_loss_and_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch0\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\IITM semester 2\\Deep Learning\\DA6401_assignment_3\\src\\vanilla_model.py:173\u001b[0m, in \u001b[0;36mVanillaSeq2Seq._compute_loss_and_metrics\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    170\u001b[0m tgt_input \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtgt_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    171\u001b[0m tgt_output \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtgt_output\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 173\u001b[0m logits, hidden, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(src_input, src_len, tgt_input)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Reshape logits and target for loss computation\u001b[39;00m\n\u001b[0;32m    176\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mtarget_vocab_size)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "loss, acc, f1 = seq_model._compute_loss_and_metrics(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93cbc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = seq_model.predict_step(batch0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d592b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds = [ddm.target_vocab.decode(seq) for seq in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d2261ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<sos>': 1,\n",
       " '<eos>': 2,\n",
       " 'a': 3,\n",
       " 'n': 4,\n",
       " 'k': 5,\n",
       " 'g': 6,\n",
       " 'i': 7,\n",
       " 't': 8,\n",
       " 'u': 9,\n",
       " 'c': 10,\n",
       " 'l': 11,\n",
       " 'e': 12,\n",
       " 'r': 13,\n",
       " 's': 14,\n",
       " 'h': 15,\n",
       " 'd': 16,\n",
       " 'b': 17,\n",
       " 'y': 18,\n",
       " 'o': 19,\n",
       " 'j': 20,\n",
       " 'z': 21,\n",
       " 'm': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'p': 25,\n",
       " 'f': 26,\n",
       " 'x': 27,\n",
       " 'q': 28}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddm.target_vocab.char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ac7c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqkqwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwb',\n",
       " 'nueqkcwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbs',\n",
       " 'eqk',\n",
       " 'ifbkqwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrw',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'nueqkcwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbs',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'hbkqwpbkqwpbkqwpbkqwpbkqwpbkqwpbkqwpbkqwpbkqwpbkqw',\n",
       " 'nueqkcwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbs',\n",
       " 'ifbkqbkqwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwb',\n",
       " 'eqk',\n",
       " 'ifbkqwlsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrwbsrw',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk',\n",
       " 'eqk']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c8bbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = attention_model.AttentionSeq2Seq(\n",
    "    input_vocab_size = len(ddm.input_vocab.idx2char),\n",
    "    target_vocab_size = len(ddm.target_vocab.idx2char),\n",
    "    embedding_dim = 256,\n",
    "    hidden_dim = 256,\n",
    "    encoder_layers = 1,\n",
    "    decoder_layers = 1,\n",
    "    encoder_dropout = 0.0,\n",
    "    decoder_dropout = 0.0,\n",
    "    encoding_unit = 'gru',\n",
    "    decoding_unit = 'gru',\n",
    "    max_len = 50,\n",
    "    beam_width = 5,\n",
    "    lr = 1e-3,\n",
    "    optimizer = 'adam',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de452e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, hidden, attn_weights = attn_model(batch0['src_input'], batch0['src_len'], batch0['tgt_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d31db79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 14, 29])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92fb6aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d806da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 14, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f087751",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, f1 = attn_model._compute_loss_and_metrics(batch0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474f9af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3544, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8e8d60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0495)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5b1ff05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0219)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38da0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, attns = attn_model.predict_step(batch0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35191b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds = [ddm.target_vocab.decode(seq) for seq in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce656150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hrkovgg',\n",
       " 'oraurrrrrrrrrrrrrrd',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'hrqiz',\n",
       " 's',\n",
       " 'qpa',\n",
       " 'iuutttttqoautttttttqoautttttttqoauttttt',\n",
       " 'sfffva',\n",
       " 'hru',\n",
       " 's',\n",
       " 'oraurrd',\n",
       " 'hrururorwur',\n",
       " 'hrqxgggg',\n",
       " 'hrdjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj',\n",
       " 'ruddjyell',\n",
       " 's',\n",
       " 'hra',\n",
       " 'iuuuttttctttcttcttcttcttcttcttcttcttcttcttcttcttct',\n",
       " 'qoauuruautttttqoorauuutttttqooruuattt',\n",
       " 'iuuuttttqoiizuuuuttttqoiizuuuuttttqoiizuu',\n",
       " 's',\n",
       " 'rd',\n",
       " 'ss',\n",
       " 's',\n",
       " 'ruutttkooreiuuuttttkoreiuuuuttttkoorauu',\n",
       " 'hhqpa',\n",
       " 's',\n",
       " 'orffffljjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj',\n",
       " 's',\n",
       " 'iuud']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b673ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4624cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 12, 10,  8,  7, 10, 14,  7,  6, 12,  7, 10, 15,  7,  9,  9, 11,  8,\n",
       "        11,  8,  6,  7,  8, 10,  7,  8, 10,  7,  7,  9, 12,  9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch0['src_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37afdb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention shape: torch.Size([11, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([50, 12])\n",
      "input src len: 12\n",
      "\n",
      "attention shape: torch.Size([2, 10])\n",
      "input src len: 10\n",
      "\n",
      "attention shape: torch.Size([2, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([2, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([6, 10])\n",
      "input src len: 10\n",
      "\n",
      "attention shape: torch.Size([2, 14])\n",
      "input src len: 14\n",
      "\n",
      "attention shape: torch.Size([4, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([50, 6])\n",
      "input src len: 6\n",
      "\n",
      "attention shape: torch.Size([7, 12])\n",
      "input src len: 12\n",
      "\n",
      "attention shape: torch.Size([8, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([2, 10])\n",
      "input src len: 10\n",
      "\n",
      "attention shape: torch.Size([14, 15])\n",
      "input src len: 15\n",
      "\n",
      "attention shape: torch.Size([28, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([9, 9])\n",
      "input src len: 9\n",
      "\n",
      "attention shape: torch.Size([50, 9])\n",
      "input src len: 9\n",
      "\n",
      "attention shape: torch.Size([13, 11])\n",
      "input src len: 11\n",
      "\n",
      "attention shape: torch.Size([2, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([4, 11])\n",
      "input src len: 11\n",
      "\n",
      "attention shape: torch.Size([50, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([50, 6])\n",
      "input src len: 6\n",
      "\n",
      "attention shape: torch.Size([50, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([3, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([6, 10])\n",
      "input src len: 10\n",
      "\n",
      "attention shape: torch.Size([3, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([2, 8])\n",
      "input src len: 8\n",
      "\n",
      "attention shape: torch.Size([50, 10])\n",
      "input src len: 10\n",
      "\n",
      "attention shape: torch.Size([6, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([2, 7])\n",
      "input src len: 7\n",
      "\n",
      "attention shape: torch.Size([50, 9])\n",
      "input src len: 9\n",
      "\n",
      "attention shape: torch.Size([2, 12])\n",
      "input src len: 12\n",
      "\n",
      "attention shape: torch.Size([7, 9])\n",
      "input src len: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(attns)):\n",
    "    print(f'attention shape: {attns[k].shape}')\n",
    "    print(f'input src len: {batch0[\"src_len\"][k]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d55e697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightningML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
